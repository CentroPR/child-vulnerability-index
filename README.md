# Child Vulnerability Index

The Children Vulnerability Index is a child-targeted version of the CDC/ATSDR's Social Vulnerability Index (SVI). The SVI is a measure of a community’s capacity to prepare and respond to natural or anthropogenic events, which may be affected by certain social conditions, including poverty, age composition, and disability. Children are dependent on their parents and community’s resilience capacity in the occurrence of a disaster. Children also have specific needs and challenges that must be tended to when preparing for, in the midst of, and after a disaster. 

The CVI measures the relative child vulnerability of every Municipio, Barrio, and Census Tract in Puerto Rico in 2021. It describes the conditions of children in Puerto Rico within households, the characteristics of households with children present, and overall household/community characteristics thay may affect them.

## Links: 
Project page @ CENTRO website: [Child Vulnerability Index](https://centropr.hunter.cuny.edu/projects/puerto-rico-children-vulnerability-index/)

Dashboard: [Child Vulnerability Index, 2021 - Dashboard](https://experience.arcgis.com/experience/ae23dd033e634edcb8ddc4bd1e98e253)

## Repository contents: 

We include the following folders and files in this repository: 

* `inputs` 
* `code`
* `outputs` 
* `CVI_data_dictionary.xlsx`

`inputs` is a folder containing files the code uses to:
- create the US Census API call to download the raw data
- map municipios, barrios, and census tracts into _Negociado para el Manejo de Emergencias y Administracion de Desastres_ (NMEAD) Operational Zones for the purposes of statistical hypothesis testing 
    
`code` is a folder containing five jupyer notebooks with code used to:
- pull the data from the US Census API
- construct the variables used to compute the CVI 
- compute the CVI
- perform statistical hypothesis testing to compare NMEAD zones' CVIs at barrio, municipio, and census tract level
- perform exploratory data analysis, compute descriptive statistics, and create data visualizations and choropleths. 
    
`outputs` is a folder that, as the code is run, is populated by the files output by the code. 

`CVI_data_dictionary.xlsx` is a Microsoft Excel Worksheet containing a data dictionary describing the variables pertaining to the CVI. 

## How to run the code? 

The code contained in the folder `code/` consists of five jupyter notebook files (`.ipynb`) containing code written in python. 

**Requirements:**

To succesfully run this code, you **need** to have the following packages in the python environment where the jupyter notebooks are run: 

- requests
- pandas
- scipy
- pickle 
- warnings 
- openpyxl
- geopandas
- matplotlib
- seaborn 

You may create a local development environment using `conda` or `virtualenv` from the `requirements.txt` file.

For Conda:

* Use `conda create --name <env_name>`, where <env_name> is the name of your virtual environment. 

* Activate your new environment: `conda activate <env_name>`

* Install pip to manage python specific requirements: `conda install pip`

* Install `requirements.txt` dependencies:  `pip install -r requirements.txt`

Once you've installed the required python packages into your python environment, open the notebook titled 
`01_data_pull_from_Census_API.ipynb` inside the `code/` folder, and run the code. 

The first three notebooks have to be run in the following order:

- `01_data_pull_from_Census_API.ipynb` 
- `02_define_variables.ipynb`
- `03_compute_CVI.ipynb`

The notebooks `04_statistical_hypothesis_testing_NMEAD_zones.ipynb` and `05_descriptive_statistics_and_EDA.ipynb` can be run **after** the outputs have been created from the first three notebooks running in the previously prescribed sequence, as they use these outputs as inputs.

The main output of this code is three flat csv files (one each corresponding to municipios, barrios, and census tracts) containing the CVI for each location. These flat files are used to populate the ESRI Enterprise Dashboard linked above. 

Other outputs in the `outputs/` folder are intermediary files (pickled pandas DataFrames) used to produce the final csv file outputs. We save these files for further exploratory data analysis, some of which we perform in notebook #5, `05_descriptive_statistics_and_EDA.ipynb`, to get aggregated data at NMEAD Operational Zone and island-wide level. 